---
title: "P8105 Homework 2"
author: "Quinton Neville"
date: "Due October 4th, 2018"
header-includes: 
  \usepackage{graphicx}
  \usepackage{float}
output:
   github_document 
---

```{r setup, echo = FALSE, warning = FALSE, message = FALSE}
#Load necessary packages
library(tidyverse)
library(readxl)
library(readr)
library(p8105.datasets)

#Controlling figure output in markdown
knitr::opts_chunk$set(
#  fig.height =   
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
#  out.height = 
)

#Set Theme for ggplot2
theme_set(theme_bw() + theme(legend.position = "bottom"))

#Set Scientific notation output for knitr
options(scipen = 999999)

```

This problem focuses on NYC Transit data; in particular, this CSV file contains information related to each entrance and exit for each subway station in NYC.

Read and clean the data; retain line, station, name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance. Convert the entry variable from character (YES vs NO) to a logical variable (the ifelse or recode function may be useful).

Write a short paragraph about this dataset – explain briefly what variables the dataset contains, describe your data cleaning steps so far, and give the dimension (rows x columns) of the resulting dataset. Are these data tidy?  

Answer the following questions using these data:  

How many distinct stations are there? Note that stations are identified both by name and by line (e.g. 125th St A/B/C/D; 125st 1; 125st 4/5); the distinct function may be useful here.  

How many stations are ADA compliant?
What proportion of station entrances / exits without vending allow entrance?
Reformat data so that route number and route name are distinct variables. How many distinct stations serve the A train? Of the stations that serve the A train, how many are ADA compliant?

#Problem 1
```{r}
#User Function to collapse route1:11 but omit NA's, returns vector of strings, for tidy data
collapse.route <- function(x){
  paste0(na.omit(x), collapse = "/")
}

#Read in & Clean Full Entry/Exit Data
nyc.transit.df <- read_csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
                     col_types = cols(
                          Route8 = col_character(),
                          Route9 = col_character(),                               #Keeping route variables consistent as chars
                          Route10 = col_character(),
                          Route11 = col_character()
                       )) %>%
                     janitor::clean_names() %>%                                     #Standardizing var names
                     select(line:route11, entry, vending, entrance_type, ada) %>%   #Selecting only necessary vars
                     mutate(entry = ifelse(entry == "YES", TRUE, FALSE),            #Casting entry as logical
                          route1 = route1 %>% toupper(),                          #Fixing incorrect lowercase e for E, route1 obs 1628
                          route5 = replace(route5, 109, NA)) %>%                  #Fixing incorrect 7 service, 6thAv-Rockefellr obs 109
                     mutate(route = apply(select(., c(route1:route11)), 1, collapse.route)) %>%  #Apply collapse, create new string var
                     select(line, station_name, route, everything(), -c(route1:route11))         #Reorder and remove old route vars
  #NOTE
#OBS 109 in original data has an extra train serviced at one of the entrances 
#(6thAV & 47-50th Sts Rockefeller Center, extra 7 train)
#OBS 1628 in original data has a miss-coded e instead of E at one entrance 
#(Queens & Forest Hills, route1 = e)

#Dimensions
dim.nyc.transit <- dim(nyc.transit.df)   #Vector of [1] Rows, [2] Columns
```

####Data Overview and Cleaning
After initial data import and cleaning, the resulting `nyc.transit.df` data frame contains `r dim.nyc.transit[1]` observations describing entries and exits for the N.Y.C. subway, in `r dim.nyc.transit[2]` variables. Considering these variables, `line` describes the vertical street station location, `station_name` the horizontal, `station_latitude` and `station_longitude` contain the respective cartographical coordinates of the observation's station, `route` describes a character string of specific trains serviced for each observation's station, `entry` describes a logical whether the observation is an entry or an "exit only", `vending` describes whether or not there are vending services available at each observation, `entrance_type` describes the type of entry/exit for each observation (stair, elevator, etc.), and `ada` describes whether or not the observation is compliant with the Americans with Disabilities Act requirements. Thus far, the cleaning steps have consisted of maintaining uniformity in character data type for `route1:11` when reading in the data, standardizing variable names with the `janitor` package, selecting only the variables of interest described above, transforming the `entry` variable to logical, fixing incorrect data points, and collapsing the route variables into one character string variable. It is important to note that here, the incorrectly recorded data points consisted of a lower case 'e' for the `route5` variable at Queens & Forest Hills station (observation 1628) and an incorrectly recorded service of the 7 train at 6th Ave./Rockefeller station (observation 109). Overall, we may describe this data as 'tidy' after collapsing the `route1:11` variables to one character string variable `route`, because every row is an observation, every column a distinct variable, and every value has a cell.  

```{r}
#Count Distinct Stations by Line, Name, and Route
distinct.stations <- nyc.transit.df %>% distinct(., line, station_name, route) %>% nrow()

#Count distinct stations ADA compiance
distinct.ada.comp <- nyc.transit.df %>%
                     distinct(., line, station_name, route, ada) %>%
                     select(ada) %>% 
                     apply(., 2, sum, na.rm = TRUE)

#Proportion of entries/exits with no vending that allow entrance
no.vend.entry <- nyc.transit.df %>%
                     filter(vending == "NO") %>%
                     select(entry) %>%
                     apply(., 2, mean)

#Pulling those which service the A train and counting how many are ADA compliant
distinct.atrain <- nyc.transit.df %>%
                     distinct(., line, station_name, route, ada) %>%
                     mutate(service_a = grepl("A", route)) %>%
                     filter(service_a == TRUE) %>%
                     nrow()

atrain.ada.comp <- nyc.transit.df %>%
                     distinct(., line, station_name, route, ada) %>%
                     mutate(service_a = grepl("A", route)) %>%
                     filter(service_a == TRUE) %>%
                     select(ada) %>%
                     apply(., 2, sum)
```

####Solutions
Using the cleaned `nyc.transit.df` dataframe described above, in combination with the `distinct()` function, we were able to obtain that there exist `r distinct.stations` distinct stations in the N.Y.C. subway system, of which `r distinct.ada.comp` are compliant with the Americans with Disabilities Act requirements. Considering all station's entries and exits, of those that do not offer vending services, only `r 100*round(no.vend.entry,5)`% offer entrance. Finally, of the `r distinct.atrain` distinct stations that service the A-train, `r atrain.ada.comp` are also compliant with ADA requirements. 

Problem2
This problem uses the Mr. Trash Wheel dataset, available as an Excel file on the course website. Please use the  HealthyHarborWaterWheelTotals2017-9-26.xlsx version.

Read and clean the Mr. Trash Wheel sheet:

specify the sheet in the Excel file and to omit columns containing notes (using the range argument and cell_cols() function)
use reasonable variable names
omit rows that do not include dumpster-specific data
rounds the number of sports balls to the nearest integer and converts the result to an integer variable (using as.integer)
Read and clean precipitation data for 2016 and 2017. For each, omit rows without precipitation data and add a variable year. Next, combine datasets and convert month to a character variable (the variable month.name is built into R and should be useful).

Write a paragraph about these data; you are encouraged to use inline R. Be sure to note the number of observations in both resulting datasets, and give examples of key variables. For available data, what was the total precipitation in 2017? What was the median number of sports balls in a dumpster in 2016?

#Problem 2
```{r warning = FALSE, error = FALSE, message = FALSE}
###Mr. Trashwheel###
#Read and Clean Mr. Trash Wheel Data
trash.wheel.df <- read_xlsx("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx",
                            sheet = "Mr. Trash Wheel", range = cell_cols("A:N")) %>%  #Select only variable columns
                  janitor::clean_names() %>%                                          #Standardize variable names
                  mutate(total = grepl("Total", month),                               #Create logical for "Total", for later filtering
                         sports_balls = as.integer(sports_balls),                     #Round sports_balls to nearet integer
                         year = ifelse(is.na(year), "2017", year)) %>%                #Impute missing year to match date variable
                  filter(total == FALSE) %>%                                          #Omit all rows with non-dumpster spec. data
                  select(-total) %>%                                                  #Remove logical total variable
                  na.omit()                                                           #Omit the remaining NA rows

#Key Stats

#Dimension
dim.trash.wheel <- dim(trash.wheel.df) #c(Rows, Cols)

#Create Tibble of Summary stats to access easily inline
total.trash.df <- trash.wheel.df %>% 
              select(weight_tons:homes_powered) %>%           #Taking all the cont. variables, calculating sum/totals, store as tibble
              apply(., 2, sum) %>% 
              t() %>%
              as.tibble()
summary.trash.df <- trash.wheel.df %>% 
              select(weight_tons:homes_powered) %>%           #Taking all the cont. variables, calc. summary stats, store as tibble
              apply(., 2, summary) %>%                        #Row bind with total
              as.tibble() %>%                                 #Add 'statistic' variable to access easiliy by filter inline
              bind_rows(., total.trash.df) %>%
              apply(., 2, round, 3) %>% as.tibble()

rownames(summary.trash.df) <- c("Min", "1Q", "Median", "Mean", "3Q", "Max", "Sum")



#Calculate Median Sports Balls in 2016
median.sports.balls <- trash.wheel.df %>%
                       filter(year == "2016") %>%
                       select(sports_balls) %>%
                       apply(., 2, median)

###2016-2017 Precipitation###
#Read 2016-2017 Precipitation Data
precip.16.df <- read_xlsx("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx",
                            sheet = "2016 Precipitation", range = "A2:B14")

precip.17.df <- read_xlsx("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx",
                            sheet = "2017 Precipitation", range = "A2:B14")

#Clean 2016-2017 Precipitation Data
precip.years <- c("2016", "2017")  #Years of Precipitation observation

precip.16.17.df <- bind_rows(precip.16.df, precip.17.df) %>%                             #Row bind 16-17 data
                   janitor::clean_names() %>%                                            #Clean names
                   mutate(month = rep(month.name, times = length(precip.years)),         #Change month variable to char
                          year = rep(precip.years, each = length(month.name))) %>%       #Create variable for year of correct length
                   filter(!is.na(total))                                                 #Omit obs. w/no total reported

#Key Stats
dim.precip.16.17 <- dim(precip.16.17.df)

#Total for both years
total.precip.df <- precip.16.17.df %>% 
                   select(total) %>%              #Taking continuous variable Total
                   apply(., 2, sum) %>%           #Counting the total over both years
                   t() %>% as.tibble()

#Summary monthly rainfall for both years & total in one tibble
summary.precip.df <- precip.16.17.df %>%
                 select(total) %>%                #Taking cont. variable Total
                 apply(., 2, summary) %>%         #Summarazing it over both years
                 as.tibble() %>%                  #Binding with total for easy inline access
                 bind_rows(., total.precip.df) 

#Name rows by summary stat. for easy access inline 
rownames(summary.precip.df) <- c("Min", "1Q", "Median", "Mean", "3Q", "Max", "Sum")


#Total Precipitation in 2017
total.precip.17 <- precip.16.17.df %>%
                   filter(year == 2017) %>%
                   select(total) %>%
                   sum()
```

####Data Overview and Cleaning
First, considering the data collected from Mr. Trash Wheel during 2014-2017, after cleaning the data, there exist `r dim.trash.wheel[1]` data collection observations in `r dim.trash.wheel[2]` variables. The cleaning process involved standardizing variable names, identifying and filtering observations for "Monthly totals", rounding sports ball values to the nearest integer, and imputing missing years for the last few observations. After the process, the data includes variables for year, month, date, weight, volume, counts of different types of trash, and approximate amount of homes powered by the electricity generated from Mr. Trash Wheel; per each trash collection observation. During the almost three years of obervation, a total of `r summary.trash.df['Sum', 'weight_tons']` tons and `r summary.trash.df['Sum', 'volume_cubic_yards']` cubic yards of trash were collected, with an average of `r summary.trash.df['Mean', 'weight_tons']` tons and `r summary.trash.df['Mean', 'volume_cubic_yards']` cubic yards collected per observation. Additionally, the largest average contributor per collection to Mr. Trash Wheel's consumption over this time frame, other than cigarette butts (`r summary.trash.df['Mean', 'cigarette_butts']`), was polystyrene trash (`r summary.trash.df['Mean', 'polystyrene']`), followed by plastic bottles, chip bags, and grocery bags, (`r summary.trash.df['Mean', 'plastic_bottles']`, `r summary.trash.df['Mean', 'chip_bags']`, `r summary.trash.df['Mean', 'grocery_bags']`), respectively. A complete table of summary statistics for the cleaned Mr. Trash Wheel data can be found in the appendix.

Next, considering the Precipitation Data collected during 2016-2017 in the same region as Mr. Trashwheel's garbage routes, there were `r dim.precip.16.17[1]` monthly observations, in `r dim.precip.16.17[2]` variables: total precipitation (in.) by month, month, and year. Cleaning this data involved reading in two data sets, 2016 and 2017 respectively, joining them by row, standardizing variable names, creating variables for month and year of precipitation observation, and removing observations with now recorded precipitation data. With respect to the cleaned data, only the first 8 out of 12 months for 2017 contained data for total precipitation by month, while the total precipitation over the observation period from Jan. 2016 - Aug. 2017 was `r summary.precip.df['Sum',]` in., with an average of `r summary.precip.df['Mean',]` in. and median of `r summary.precip.df['Median',]` in. per month. A complete table of summary statistics for total precipitation over this time frame can be found in the appendix. 

####Solutions
With respect to the two cleaned data frames concerning Mr. Trash Wheel and monthly precipitation, outlined above, we were able to obtain that there was an observed total precipitation of `r total.precip.17` in. in 2017, while the median number of sports balls collected by Mr. Trash Wheel was `r median.sports.balls` in 2016. 



#Problem 3

This problem uses the BRFSS data. DO NOT include this dataset in your local data directory; instead, load the data from the  p8105.datasets package.

For this question:

format the data to use appropriate variable names;
focus on the “Overall Health” topic
exclude variables for class, topic, question, sample size, and everything from lower confidence limit to GeoLocation
structure data so that values for Response (“Excellent” to “Poor”) are column names / variables which indicate the proportion of subjects with each response (which are values of Data_value in the original dataset)
create a new variable showing the proportion of responses that were “Excellent” or “Very Good”
Using this dataset, do or answer the following:

How many unique locations are included in the dataset? Is every state represented? What state is observed the most?
In 2002, what is the median of the “Excellent” response value?
Make a histogram of “Excellent” response values in the year 2002.
Make a scatterplot showing the proportion of “Excellent” response values in New York County and Queens County (both in NY State) in each year from 2002 to 2010.

```{r}
#Call data from p8105 library
data("brfss_smart2010")

#Clean and Manipulate BRFSS data
brfss.df <- brfss_smart2010 %>%
            janitor::clean_names() %>%
            filter(topic == "Overall Health") %>%
            select(-c(class, topic, question, sample_size, confidence_limit_low:geo_location)) %>%
            spread(key = response, value = data_value) %>% 
            janitor::clean_names() %>%
            mutate(locationdesc = substring(locationdesc, 6)) %>%
            rename(state = locationabbr, county = locationdesc) %>%
            select(year:county, excellent, very_good, good, fair, poor) %>%
            mutate(excellent_or_very_good = excellent + very_good)

#Distinct Locations/States
distinct.locations <-  brfss.df %>% distinct(., state, county) %>% nrow() #404

distinct.states <- brfss.df %>% distinct(., state) %>% nrow() 

#Which State Observed the Most
max.state.index <- brfss.df %>% count(state) %>% select(n) %>% apply(., 2, which.max)
state.max.obs <- brfss.df %>% count(state) %>% select(state) %>% slice(., max.state.index) %>% as.character()

#2002 Median 'Excellent` response
med.excel.2002 <- brfss.df %>% 
                  filter(year == 2002) %>%
                  select(excellent) %>%
                  apply(., 2, median, na.rm = T)

#Histogram of Excellent Responses in 2002
hist.excel.02 <- brfss.df %>%
                 filter(year == 2002) %>%
                 ggplot() +
                 geom_histogram(aes(x = excellent),
                                color = "black", fill = "lightblue") +
                 labs(
                   x = "Percentage Excellent Response (%)",
                   y = "Count",
                   title = "Histogram of % Excellent Response, 2002"
                 )

hist.excel.02

#Scatter of Prop. Excellent in NY County and Queens County, from 2002 to 2010
scatter.excel.02.10 <- brfss.df %>%
                       filter(county == "New York County" |
                              county == "Queens County") %>%
                       ggplot(aes(x = year, y = excellent, color = county)) +
                       geom_point(alpha = 0.9, size = 2) +
                       labs(
                         x = "Year",
                         y = "Proportion Excellent Responses (%)",
                         title = "Scatter Plot of % Excellent Responses"
                       ) +
                       scale_color_manual(
                         name = "County",
                         values = c("Lightblue", "Purple"))
scatter.excel.02.10


                      

```


